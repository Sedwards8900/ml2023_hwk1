{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question/Problem description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Problem description:\n",
    "\n",
    "For this problem, you need to download the Breast Cancer dataset from course webpage. \n",
    "The description of this dataset is in https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original). \n",
    "I have removed the records with missing values for you. Here, you will obtain the learning curves (accuracy vs. \n",
    "training data size). Implement a logistic regression classifier with the assumption that each attribute value \n",
    "for a particular record is independently generated. You should submit the code electronically to iCollege.\n",
    "\n",
    "1.\t(10 points) Briefly describe how you implement it by giving the pseudocode. The pseudocode must include \n",
    "equations for estimating the classification parameters and for classifying a new example. Re- member, this \n",
    "should not be a printout of your code, but a high-level outline.\n",
    "\n",
    "2.  (15 points) Plot a learning curve: the accuracy vs. the size of the training data. Generate six points on \n",
    "the curve, using [.01 .02 .03 .125 .625 1] fractions of your training set and testing on the full test set each \n",
    "time. Average your results over 5 random splits of the data into a training and test set (always keep 2/3 of \n",
    "the data for training and 1/3 for testing, but randomize over which points go to training set and which to testing). \n",
    "This averaging will make your results less dependent on the order of records in the file. Specify your choice of \n",
    "regularization parameters and keep those parameters constant for these tests. A typical choice of constants would \n",
    "be λ = 0 (no regularization).\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1. Sample code number: id number\n",
    "2. Clump Thickness: 1 - 10\n",
    "3. Uniformity of Cell Size: 1 - 10\n",
    "4. Uniformity of Cell Shape: 1 - 10\n",
    "5. Marginal Adhesion: 1 - 10\n",
    "6. Single Epithelial Cell Size: 1 - 10\n",
    "7. Bare Nuclei: 1 - 10\n",
    "8. Bland Chromatin: 1 - 10\n",
    "9. Normal Nucleoli: 1 - 10\n",
    "10. Mitoses: 1 - 10\n",
    "11. Class: (2 for benign, 4 for malignant)\n",
    "\n",
    "\n",
    "In summary, what we need to get:\n",
    "\n",
    "    - Obtain learning curves (accuracy vs training data size)\n",
    "    - Implement Logistic Regression Classifier\n",
    "\t        Assume -> attribute values for particular record = independently generated\n",
    "    - Equations for estimating the classification parameters\n",
    "    - Equations for classifying a new example\n",
    "\n",
    "Please note, code development was based on tutorial at https://realpython.com/logistic-regression-python/\n",
    "\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Access data including number of attributes, total number of samples - X values, total number of Y values, all in the form of a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scipy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#Load the data file\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m mat\u001b[39m=\u001b[39mscipy\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mloadmat(\u001b[39m'\u001b[39m\u001b[39mdata_breastcancer.mat\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39m# print(\"full data: \", mat['data'])\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mkeys: \u001b[39m\u001b[39m\"\u001b[39m, mat\u001b[39m.\u001b[39mkeys())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scipy' is not defined"
     ]
    }
   ],
   "source": [
    "#Load the data file\n",
    "mat=scipy.io.loadmat('data_breastcancer.mat')\n",
    "# print(\"full data: \", mat['data'])\n",
    "print(\"keys: \", mat.keys())\n",
    "\n",
    "#Number of samples\n",
    "n = mat['data']['n'][0][0][0][0]\n",
    "print(\"sample#: \", n)\n",
    "\n",
    "#Number of attributes\n",
    "d = mat['data']['d'][0][0][0][0]\n",
    "print(\"attributes#: \", d)\n",
    "\n",
    "#Input data\n",
    "X = mat['data']['X'][0][0]\n",
    "print(\"input data\", X)\n",
    "print(\"shape: \", X.shape)\n",
    "print(\"type: \", X.dtype, \" and: \", type(X[0]))\n",
    "\n",
    "#Output labels\n",
    "Y = mat['data']['Y'][0][0]\n",
    "# print(\"output labels: \", Y)\n",
    "print(\"type: \", Y.dtype, \" and: \", type(X[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create the sigmoid function for your binary logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The logistic regression function 𝑝(𝐱) is the sigmoid function of 𝑓(𝐱): 𝑝(𝐱) = 1 / (1 + exp(−𝑓(𝐱))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create and define the desired classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create an instance of logistic regression and bind references to the variable model \n",
    "\n",
    "Solver is a string ('liblinear' by default) that decides what solver to use for fitting \n",
    "the model. Other options are 'newton-cg', 'lbfgs', 'sag', and 'saga'.\n",
    "\n",
    "Random_state is an integer, an instance of numpy. RandomState, or None (default) that defines \n",
    "what pseudo-random number generator to use.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Logistic regression determines the best predicted weights 𝑏₀, 𝑏₁, …, 𝑏ᵣ such that \n",
    "the function 𝑝(𝐱) is as close as possible to all actual responses 𝑦ᵢ, 𝑖 = 1, …, 𝑛, \n",
    "where 𝑛 is the number of observations. \n",
    "\n",
    "The process of calculating the best weights using available observations is called \n",
    "model training or fitting.\n",
    "\n",
    "Proceed to fit the X and Y values into the model by using .fit() function, which \n",
    "takes x and y. The returned value is the model instance.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=0, solver='liblinear')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Get the attributes of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y values:  [0 1]\n",
      "[-6.25906995] [[ 0.24515516  0.16142571  0.27161639  0.17946675 -0.04158784  0.34698954\n",
      "   0.1815928   0.19130598  0.20634236]]\n"
     ]
    }
   ],
   "source": [
    "# Use the .classes_ function to check for the array of distint values that y takes:\n",
    "# aka. is the result binary - binary classification\n",
    "print(\"y values: \", model.classes_)\n",
    "\n",
    "# Use .intercept_ to check value of slope b1 and the intercept b0 of the linear function:\n",
    "print(model.intercept_, model.coef_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    ".predict_proba(x) allows you to check the performance of the model. \n",
    "It returns a matrix of probabilities where each row corresponds to a single\n",
    "observation, and the first column indicates whether the output is 0 [1-p(x)]\n",
    "and the second if the output is 1 [p(x)]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.96137797 0.03862203]\n",
      " [0.12912459 0.87087541]\n",
      " [0.96636146 0.03363854]\n",
      " ...\n",
      " [0.01256907 0.98743093]\n",
      " [0.0576589  0.9423411 ]\n",
      " [0.03108921 0.96891079]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict_proba(X))\n",
    "\n",
    "# .predict(x) -> Get actual predictions, based on probability matrix and the values of p(x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"input data\", X[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the best weights, you usually maximize the log-likelihood function (LLF) \n",
    "# for all observations 𝑖 = 1, …, 𝑛. This method is called the maximum likelihood \n",
    "# estimation and is represented by the equation LLF = Σᵢ(𝑦ᵢ log(𝑝(𝐱ᵢ)) + (1 − 𝑦ᵢ) log(1 − 𝑝(𝐱ᵢ)))."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
